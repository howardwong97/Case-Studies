{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analysis-of-product-reviews\" data-toc-modified-id=\"Analysis-of-product-reviews-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analysis of product reviews</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-the-data\" data-toc-modified-id=\"Reading-the-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Reading the data</a></span></li><li><span><a href=\"#Part-(a)-and-Part-(b)\" data-toc-modified-id=\"Part-(a)-and-Part-(b)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Part (a) and Part (b)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Implementation\" data-toc-modified-id=\"Code-Implementation-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Code Implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lemmatization-and-Basic-Preprocessing\" data-toc-modified-id=\"Lemmatization-and-Basic-Preprocessing-2.2.1.1\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>Lemmatization and Basic Preprocessing</a></span></li><li><span><a href=\"#Compute-tf-idf-scores\" data-toc-modified-id=\"Compute-tf-idf-scores-2.2.1.2\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>Compute tf-idf scores</a></span></li><li><span><a href=\"#Big-O-Time-and-Space-Complexity\" data-toc-modified-id=\"Big-O-Time-and-Space-Complexity-2.2.1.3\"><span class=\"toc-item-num\">2.2.1.3&nbsp;&nbsp;</span>Big-O Time and Space Complexity</a></span></li></ul></li></ul></li><li><span><a href=\"#Part-(c)\" data-toc-modified-id=\"Part-(c)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Part (c)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Implementation\" data-toc-modified-id=\"Code-Implementation-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Code Implementation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of product reviews\n",
    "\n",
    "The `reviews_sentiment.csv` file contains product reviews for a brand of evaporative air coolers, along with the ground-truth review sentiments that may be positive or negative (none are neutral). When loading the data, ensure that you use a pipe (|) delimiter and `utf-8` encoding.\n",
    "\n",
    "## Reading the data\n",
    "\n",
    "I read the dataset into a `pd.DataFrame` and familiarise myself with its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it is so much better than the one it replaced ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So far I think it is a good purchase. I haven'...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It doesn't match on advertise, it just work as...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Works like a charm.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This grill cover was perfect and easy to snap on</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  it is so much better than the one it replaced ...  Positive\n",
       "1  So far I think it is a good purchase. I haven'...  Positive\n",
       "2  It doesn't match on advertise, it just work as...  Negative\n",
       "3                                Works like a charm.  Positive\n",
       "4   This grill cover was perfect and easy to snap on  Positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/task2/reviews_sentiment.csv', sep='|', encoding='utf-8')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of characters: 244\n",
      "Average number of words: 47 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How long is each review?\n",
    "print('Average number of characters:', round(df['review'].str.len().mean()))\n",
    "print('Average number of words:', round(df['review'].apply(lambda x: len(x.split())).mean()), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I look at the distribution of 'Positive' reviews versus 'Negative' reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive    5276\n",
      "Negative    1780\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many Positive vs. Negative?\n",
    "print(df['sentiment'].value_counts())\n",
    "df['sentiment'].value_counts().plot(kind='bar', color=['tab:green', 'tab:red'], figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a skewed dataset with many more *positive* reviews than there are *negative* reviews. This is something to bear in mind throughout the analysis.\n",
    "\n",
    "Before proceeding, I also split the dataset into train and test sets. I check to make sure that the relative proportion between positive and negative reviews for each partition is representative of the full sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5644\n",
      "Training Positive Ratio: 0.7475194897236003 \n",
      "\n",
      "Test samples: 1412\n",
      "Test Positive Ratio: 0.7485835694050992 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=123456)\n",
    "print('Training samples:', len(df_train))\n",
    "print('Training Positive Ratio:', df_train['sentiment'].value_counts()['Positive'] / df_train['sentiment'].value_counts().sum(), '\\n')\n",
    "\n",
    "print('Test samples:', len(df_test))\n",
    "print('Test Positive Ratio:', df_test['sentiment'].value_counts()['Positive'] / df_test['sentiment'].value_counts().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a) and Part (b)\n",
    "\n",
    "Perform basic tokenization and normalization on the product reviews. At a minimum, you should:\n",
    "\n",
    "- standardize the word case (i.e. upper or lower case);\n",
    "- remove punctuation and common stop words; and\n",
    "- perform *some* stemming or lemmatization to reduce the number of unique tokens.\n",
    "\n",
    "Use the overall statistics of the corpus of reviews to guide this step. Your cleaned output should be a *list of tokens representing each review*.\n",
    "\n",
    "Let the set of all unique terms (i.e. the dictionary) be $\\mathcal{T}$ , and the set of all reviews (i.e. corpus of documents) be $\\mathcal{D}$. For each term $t ∈ \\mathcal{T}$ and review $d ∈ \\mathcal{D}$, define the term frequency–inverse document frequency (tf-idf) score\n",
    "\n",
    "\\begin{align}\n",
    "\\text{tf-idf}_{t,d} &= \\text{tf}_{t,d} * \\text{idf}_t \\\\\n",
    "&= \\left( \\frac{1}{|d|} \\sum_{i∈d} \\mathbf{1}_{\\{i=t\\}} \\right) * \\left(\\log\\frac{|\\mathcal{D}|}{|\\{ d ∈ \\mathcal{D} : t ∈ d \\}|}\\right),\n",
    "\\end{align}\n",
    "\n",
    "where | · | denotes the size of a set, and $\\mathbf{1}_{\\{·\\}}$ denotes the indicator function. Notice that\n",
    "$\\text{tf}_{t,d}$ simply counts the number of times term $t$ appears in review $d$, normalized by the number of terms in $d$, while $\\text{idf}_t$ is inversely proportional to the number of reviews that $t$ appears in, scaled by the total number of reviews.\n",
    "\n",
    "> Q) Using appropriate data structures, write an algorithm to compute the $|\\mathcal{D}| * |\\mathcal{T}|$ matrix of tf-idf scores $\\mathbf{X}$ where\n",
    "\n",
    "\\begin{equation}\n",
    "X_{d,t} = \\text{tf-idf}_{t,d}.\n",
    "\\end{equation}\n",
    "\n",
    "You may restrict your dictionary to only terms that occur at least a certain number of times throughout the corpus, bearing in mind any impact on your work in part(c).\n",
    "\n",
    "> Q) Assuming that hashing takes constant time and defining any additional notation where necessary, derive the big-$\\mathcal{O}$ time and space complexity of your solution.\n",
    "\n",
    "### Code Implementation\n",
    "\n",
    "#### Lemmatization and Basic Preprocessing\n",
    "\n",
    "Briefly, the steps implemented in the `tokenizer()` function are as follows:\n",
    "\n",
    "1. Take in an array of all the reviews\n",
    "2. Tokenize and lemmatize each sentence\n",
    "3. Clean the text - punctuation, numbers, and standardise lower case\n",
    "4. Remove words that are less than two characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per sentence: 20\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text_array):\n",
    "    nlp = English()\n",
    "    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "    token_list = []\n",
    "    for text in text_array:\n",
    "        tokens = tokenizer(text)  # tokenize text\n",
    "        lemm = [token.lemma_ for token in tokens if token.is_stop is False]\n",
    "        return_list = []\n",
    "        for i in range(len(lemm)):\n",
    "            temp_text = re.sub('<[^>]*>', '', lemm[i])\n",
    "            temp_text = re.sub(r'[0-9]+', '', lemm[i])\n",
    "            temp_text = re.sub('[\\W]+', '', temp_text.lower())\n",
    "            if len(temp_text) > 1:\n",
    "                return_list.append(temp_text)\n",
    "        token_list.append(return_list)\n",
    "    return token_list\n",
    "\n",
    "tokenized_reviews= tokenizer(df_train['review'].values)\n",
    "\n",
    "avg = 0\n",
    "for i in tokenized_reviews:\n",
    "    avg += len(i)\n",
    "avg = avg / len(tokenized_reviews)\n",
    "print('Average tokens per sentence:', round(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfvectorizer(tokenized_reviews, dict_size=500):\n",
    "    \n",
    "    wordfreq, word_idf_values, word_tf_values = {}, {}, {}\n",
    "    tfidf_scores = []\n",
    "    \n",
    "    # First, get the overall word frequencies of each word\n",
    "    for sent in tokenized_reviews:\n",
    "        \n",
    "        for token in sent:\n",
    "            if token not in wordfreq.keys():\n",
    "                wordfreq[token] = 1\n",
    "            else:\n",
    "                wordfreq[token] += 1\n",
    "    \n",
    "    # Keep the words that occur at least 500 times (default)\n",
    "    most_freq = heapq.nlargest(dict_size, wordfreq, key=wordfreq.get)\n",
    "    \n",
    "    for token in most_freq:\n",
    "        reviews_containing_word = 0\n",
    "        sent_tf_vector = []\n",
    "        \n",
    "        for sent in tokenized_reviews:\n",
    "            doc_freq = 0\n",
    "            if token in sent:\n",
    "                reviews_containing_word += 1\n",
    "            for word in sent:\n",
    "                if word == token:\n",
    "                    doc_freq += 1\n",
    "            word_tf = doc_freq / len(tokenized_reviews)\n",
    "            sent_tf_vector.append(word_tf)\n",
    "        \n",
    "        #'term-frequency'\n",
    "        word_tf_values[token] = sent_tf_vector\n",
    "        \n",
    "        # inverse-docyument-frequency\n",
    "        word_idf_values[token] = np.log(len(tokenized_reviews) / (1 + reviews_containing_word)) \n",
    "    \n",
    "    for token in word_tf_values.keys():\n",
    "        \n",
    "        tfidf_sentences = []\n",
    "        \n",
    "        for tf_sentence in word_tf_values[token]:\n",
    "            tf_idf_score = tf_sentence * word_idf_values[token]\n",
    "            tfidf_sentences.append(tf_idf_score)\n",
    "            \n",
    "        tfidf_scores.append(tfidf_sentences)\n",
    "    \n",
    "    return np.asarray(tfidf_scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function above is correct, we expect to see a result with dimensions *length of training set x dictionary size (500)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5644, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidfvectorizer(tokenized_reviews)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big-O Time and Space Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: 0.4629499912261963\n",
      "200: 0.9171183109283447\n",
      "300: 1.3614447116851807\n",
      "400: 1.8320987224578857\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "X = tfidfvectorizer(tokenized_reviews[:1000])\n",
    "print('100:', time.time() - start)\n",
    "\n",
    "start=time.time()\n",
    "X = tfidfvectorizer(tokenized_reviews[:2000])\n",
    "print('200:', time.time() - start)\n",
    "\n",
    "start=time.time()\n",
    "X = tfidfvectorizer(tokenized_reviews[:3000])\n",
    "print('300:', time.time() - start)\n",
    "\n",
    "start=time.time()\n",
    "X = tfidfvectorizer(tokenized_reviews[:4000])\n",
    "print('400:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that hashing takes constant time,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{Big}-\\mathcal{O}\\text{ complexity} = \\mathcal{O}(n)\\\\\n",
    "    \\text{Space Complexity} = \\mathcal{O}(n)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c)\n",
    "\n",
    "Fit a classifier of your choice to predict review sentiment using the feature matrix $X$.\n",
    "\n",
    "i) Perform any necessary pre-processing to ensure reliable model fitting and evaluation.\n",
    "\n",
    "ii) Also perform hyperparameter tuning for at least one hyperparameter that is important to model performance.\n",
    "\n",
    "iii) Document and briefly discuss any findings and challenges, linking them to potential\n",
    "business questions that your predictions might be used for.\n",
    "\n",
    "### Code Implementation\n",
    "\n",
    "I will be using a Support Vector Classifier. Though the fit time scales quadratically with the number of samples, this is a relatively small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data as described in previous sections\n",
    "X_train = df_train['review'].values\n",
    "X_train_tokenized = tokenizer(X_train)\n",
    "X_train_processed = tfidfvectorizer(X_train_tokenized)\n",
    "\n",
    "y_train = df_train['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for gridsearch\n",
    "param_grid = {\n",
    "    'C': [1, 0.1, 0.01, 0.001],\n",
    "    'gamma': ['scale', 'auto']}\n",
    "\n",
    "search = GridSearchCV(SVC(), param_grid=param_grid)\n",
    "search.fit(X_train_processed, y_train)\n",
    "print('Best parameters:')\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7475194897236003\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=1, gamma='scale', kernel='linear')\n",
    "model.fit(X_train_processed, y_train)\n",
    "print('Train accuracy:', model.score(X_train_processed, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use the model to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['review'].values\n",
    "X_test_tokenized = tokenizer(X_test)\n",
    "X_test_processed = tfidfvectorizer(X_test_tokenized)\n",
    "\n",
    "y_test = df_test['sentiment'].values\n",
    "\n",
    "y_predict = model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485835694050992"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test == y_predict) / len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
